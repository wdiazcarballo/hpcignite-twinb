# DREAM'26 Twin-B Experiments

This folder contains experiments and analysis for the DREAM'26 conference submission on the Twin-B building co-simulation platform.

## Overview

The Twin-B system couples EnergyPlus building energy modeling with Mesa agent-based modeling in a distributed HPC environment. These experiments establish baseline performance metrics and identify optimization opportunities for energy-aware data movement.

## Quick Start

### 1. Submit Experiments

```bash
cd dream26

# Experiment 1: Platform capability profiling (~30 minutes)
./submit_exp1.sh

# Experiment 1b: Enhanced platform capability with energy profiling (~1 hour)
./submit_exp1b.sh

# Experiment 2: Baseline simulation with profiling (~2 hours)
./submit_exp2.sh

# Monitor jobs
squeue -u $USER
```

**Recommendation**: Run **Experiment 1b** (enhanced) instead of Experiment 1 for complete Section 4 analysis.

**Note:** Helper scripts (`submit_exp1.sh`, `submit_exp2.sh`) automatically create directories and organize outputs.

### 2. Check Results

```bash
# Check experiment 1 output (simple structure - no subdirectories!)
tail -f dream26/exp1_XXXXX.out

# Check experiment 2 output
tail -f dream26/exp2_XXXXX.out
```

### 3. Analyze Results

```bash
# Run analysis on experiment 2 results (simple paths!)
cd dream26
python analyze_baseline.py exp2_XXXXX
```

## Environment Setup

The two experiments use different Python environments:

- **Experiment 1**: Uses system-provided `pytorch-2.2.2` conda environment
  - Pre-configured by LANTA administrators
  - Includes PyTorch with CUDA support
  - Faster startup, no installation needed

- **Experiment 2**: Uses project-specific virtual environment at `/project/lt200291-ignite/Project_chomwong/.venv`
  - Includes Twin-B dependencies (Mesa, EnergyPlus API, etc.)
  - Auto-installs PyTorch if missing

## Files in This Directory

### Experiment Scripts
- **`experiment1_platform_capability.slurm`** - Platform benchmarking job (uses system PyTorch)
- **`experiment1b_enhanced_platform_capability.slurm`** - **Enhanced** platform profiling with energy analysis (recommended)
- **`experiment2_baseline_simulation.slurm`** - Baseline Twin-B simulation with profiling (uses project venv)

### What's New in Experiment 1b?
Experiment 1b addresses all gaps from Experiment 1 for complete Section 4 analysis:
- ✅ **Fixed GPU power monitoring** (gpu_metrics_load.csv issue resolved)
- ✅ **Small transfer testing** (1B to 1MB, including 37-byte transfers from Section 4)
- ✅ **Energy cost analysis** (joules per operation type)
- ✅ **Mixed workload profiling** (compute + transfer patterns)

See `EXPERIMENT1B_ENHANCEMENTS.md` for detailed analysis.

### Analysis
- **`analyze_baseline.py`** - Automated analysis script for experiment 2
  - Analyzes GPU metrics, agent simulation, profiling data
  - Generates plots and summary reports
  - Compares results with DREAM'26 paper metrics

### Documentation
- **`EXPERIMENTS.md`** - Detailed documentation for both experiments
- **`README.md`** - This file

## Output Directories

### Experiment 1 Outputs
```
dream26/exp1_<job_id>/
├── gpu_compute_results.json
├── memory_bandwidth_results.json
├── ddp_communication_results.json
├── gpu_metrics_idle.csv
└── gpu_metrics_load.csv
```

### Experiment 2 Outputs
```
dream26/exp2_<job_id>/
├── EXPERIMENT_SUMMARY.md
├── twinb_baseline_profile.nsys-rep  ← Open in Nsight Systems GUI
├── cuda_api_summary.csv
├── gpu_kernel_summary.csv
├── memory_operation_summary.csv
├── mesa_agent_results_baseline.csv
├── gpu_metrics_baseline.csv
├── analysis_summary.json            ← Generated by analyze_baseline.py
├── gpu_metrics_timeline.png         ← Generated by analyze_baseline.py
└── ac_usage_over_time.png          ← Generated by analyze_baseline.py
```

## Key Metrics to Compare with DREAM'26 Paper

| Metric | DREAM'26 Paper | Check In |
|--------|----------------|----------|
| cudaStreamSynchronize overhead | 66.3% of CUDA API time | `cuda_api_summary.csv` |
| NCCL AllGather | 32.7% of GPU kernel time | `gpu_kernel_summary.csv` |
| NCCL AllReduce | 31.7% of GPU kernel time | `gpu_kernel_summary.csv` |
| Avg H2D transfer size | 37.5 bytes | `memory_operation_summary.csv` |
| Primary CPU process | 96.99% | Simulation logs |
| Secondary CPU process | 2.02% | Simulation logs |

## Troubleshooting

**Job won't start:**
```bash
squeue -u $USER       # Check queue
sinfo -p gpu          # Check GPU partition availability
```

**Out of memory:**
- Edit `config.yaml` to reduce simulation steps
- Edit `agents.json` to reduce agent count

**NCCL timeout:**
- Increase `TORCH_NCCL_TIMEOUT` in experiment script

**Missing results:**
- Check error log: `logs/exp2_baseline_XXXXX.err`
- Verify EnergyPlus paths in script

## Next Steps After Baseline

1. Review `EXPERIMENT_SUMMARY.md` in results directory
2. Run `analyze_baseline.py` for automated analysis
3. Open `.nsys-rep` in Nsight Systems GUI for detailed profiling
4. Identify top bottlenecks from analysis
5. Design optimization experiments based on findings

## References

- Full documentation: `EXPERIMENTS.md`
- Project architecture: `../CLAUDE.md`
- DREAM'26 submission: `../DREAM'26_Twin-B_Submission.docx`

---

*For detailed instructions and troubleshooting, see EXPERIMENTS.md*

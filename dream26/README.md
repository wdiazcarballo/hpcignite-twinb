# DREAM'26 Twin-B Experiments

This folder contains experiments and analysis for the DREAM'26 conference submission on the Twin-B building co-simulation platform.

## Overview

The Twin-B system couples EnergyPlus building energy modeling with Mesa agent-based modeling in a distributed HPC environment. These experiments establish baseline performance metrics and identify optimization opportunities for energy-aware data movement.

## Quick Start

### 1. Submit Experiments

```bash
cd dream26

# Experiment 1: Platform capability profiling (~30 minutes)
sbatch experiment1_platform_capability.slurm

# Experiment 2: Baseline simulation with profiling (~2 hours)
sbatch experiment2_baseline_simulation.slurm

# Monitor jobs
squeue -u $USER
```

### 2. Check Results

```bash
# Check experiment 1 output (simple structure - no subdirectories!)
tail -f dream26/exp1_XXXXX.out

# Check experiment 2 output
tail -f dream26/exp2_XXXXX.out
```

### 3. Analyze Results

```bash
# Run analysis on experiment 2 results (simple paths!)
cd dream26
python analyze_baseline.py exp2_XXXXX
```

## Files in This Directory

### Experiment Scripts
- **`experiment1_platform_capability.slurm`** - Platform benchmarking job
- **`experiment2_baseline_simulation.slurm`** - Baseline Twin-B simulation with profiling

### Analysis
- **`analyze_baseline.py`** - Automated analysis script for experiment 2
  - Analyzes GPU metrics, agent simulation, profiling data
  - Generates plots and summary reports
  - Compares results with DREAM'26 paper metrics

### Documentation
- **`EXPERIMENTS.md`** - Detailed documentation for both experiments
- **`README.md`** - This file

## Output Directories

### Experiment 1 Outputs
```
dream26/exp1_<job_id>/
├── gpu_compute_results.json
├── memory_bandwidth_results.json
├── ddp_communication_results.json
├── gpu_metrics_idle.csv
└── gpu_metrics_load.csv
```

### Experiment 2 Outputs
```
dream26/exp2_<job_id>/
├── EXPERIMENT_SUMMARY.md
├── twinb_baseline_profile.nsys-rep  ← Open in Nsight Systems GUI
├── cuda_api_summary.csv
├── gpu_kernel_summary.csv
├── memory_operation_summary.csv
├── mesa_agent_results_baseline.csv
├── gpu_metrics_baseline.csv
├── analysis_summary.json            ← Generated by analyze_baseline.py
├── gpu_metrics_timeline.png         ← Generated by analyze_baseline.py
└── ac_usage_over_time.png          ← Generated by analyze_baseline.py
```

## Key Metrics to Compare with DREAM'26 Paper

| Metric | DREAM'26 Paper | Check In |
|--------|----------------|----------|
| cudaStreamSynchronize overhead | 66.3% of CUDA API time | `cuda_api_summary.csv` |
| NCCL AllGather | 32.7% of GPU kernel time | `gpu_kernel_summary.csv` |
| NCCL AllReduce | 31.7% of GPU kernel time | `gpu_kernel_summary.csv` |
| Avg H2D transfer size | 37.5 bytes | `memory_operation_summary.csv` |
| Primary CPU process | 96.99% | Simulation logs |
| Secondary CPU process | 2.02% | Simulation logs |

## Troubleshooting

**Job won't start:**
```bash
squeue -u $USER       # Check queue
sinfo -p gpu          # Check GPU partition availability
```

**Out of memory:**
- Edit `config.yaml` to reduce simulation steps
- Edit `agents.json` to reduce agent count

**NCCL timeout:**
- Increase `TORCH_NCCL_TIMEOUT` in experiment script

**Missing results:**
- Check error log: `logs/exp2_baseline_XXXXX.err`
- Verify EnergyPlus paths in script

## Next Steps After Baseline

1. Review `EXPERIMENT_SUMMARY.md` in results directory
2. Run `analyze_baseline.py` for automated analysis
3. Open `.nsys-rep` in Nsight Systems GUI for detailed profiling
4. Identify top bottlenecks from analysis
5. Design optimization experiments based on findings

## References

- Full documentation: `EXPERIMENTS.md`
- Project architecture: `../CLAUDE.md`
- DREAM'26 submission: `../DREAM'26_Twin-B_Submission.docx`

---

*For detailed instructions and troubleshooting, see EXPERIMENTS.md*

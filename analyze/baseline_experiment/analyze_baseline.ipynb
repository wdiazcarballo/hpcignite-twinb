{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Twin-B Experiment Analysis\n",
    "\n",
    "This notebook analyzes the results from Experiment 2: Baseline Twin-B simulation with profiling.\n",
    "\n",
    "## Analysis Goals\n",
    "1. Identify CPU-GPU synchronization bottlenecks\n",
    "2. Measure NCCL communication overhead\n",
    "3. Analyze memory transfer patterns\n",
    "4. Compare against DREAM'26 paper metrics\n",
    "5. Establish baseline for future optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Update this path to your experiment results directory\n",
    "RESULTS_DIR = Path('../../experiment2_results/baseline_XXXXX')  # Replace XXXXX with job ID\n",
    "\n",
    "print(f\"Analyzing results from: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPU metrics\n",
    "gpu_baseline = pd.read_csv(RESULTS_DIR / 'gpu_metrics_baseline.csv')\n",
    "gpu_profiled = pd.read_csv(RESULTS_DIR / 'gpu_metrics_profiled.csv')\n",
    "\n",
    "# Clean column names\n",
    "gpu_baseline.columns = gpu_baseline.columns.str.strip()\n",
    "gpu_profiled.columns = gpu_profiled.columns.str.strip()\n",
    "\n",
    "print(\"GPU Metrics - Baseline Run\")\n",
    "print(f\"Samples collected: {len(gpu_baseline)}\")\n",
    "print(f\"Duration: ~{len(gpu_baseline)} seconds\")\n",
    "print(f\"\\nAverage metrics:\")\n",
    "print(f\"  Power draw: {gpu_baseline['power_draw_w'].mean():.2f}W (max: {gpu_baseline['power_draw_w'].max():.2f}W)\")\n",
    "print(f\"  GPU utilization: {gpu_baseline['gpu_utilization_pct'].mean():.2f}%\")\n",
    "print(f\"  Memory used: {gpu_baseline['memory_used_mb'].mean():.2f}MB\")\n",
    "print(f\"  Temperature: {gpu_baseline['temperature_c'].mean():.2f}째C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GPU metrics over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Separate by GPU\n",
    "for gpu_id in gpu_baseline['gpu_id'].unique():\n",
    "    gpu_data = gpu_baseline[gpu_baseline['gpu_id'] == gpu_id]\n",
    "    \n",
    "    # Power\n",
    "    axes[0, 0].plot(gpu_data['power_draw_w'], label=f'GPU {gpu_id}', alpha=0.7)\n",
    "    # Utilization\n",
    "    axes[0, 1].plot(gpu_data['gpu_utilization_pct'], label=f'GPU {gpu_id}', alpha=0.7)\n",
    "    # Memory\n",
    "    axes[1, 0].plot(gpu_data['memory_used_mb'], label=f'GPU {gpu_id}', alpha=0.7)\n",
    "    # Temperature\n",
    "    axes[1, 1].plot(gpu_data['temperature_c'], label=f'GPU {gpu_id}', alpha=0.7)\n",
    "\n",
    "axes[0, 0].set_title('Power Draw Over Time')\n",
    "axes[0, 0].set_ylabel('Power (W)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].set_title('GPU Utilization Over Time')\n",
    "axes[0, 1].set_ylabel('Utilization (%)')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[1, 0].set_title('Memory Usage Over Time')\n",
    "axes[1, 0].set_ylabel('Memory (MB)')\n",
    "axes[1, 0].set_xlabel('Sample')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].set_title('Temperature Over Time')\n",
    "axes[1, 1].set_ylabel('Temperature (째C)')\n",
    "axes[1, 1].set_xlabel('Sample')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'gpu_metrics_timeline.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agent Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load agent results\n",
    "agents_df = pd.read_csv(RESULTS_DIR / 'mesa_agent_results_baseline.csv')\n",
    "\n",
    "print(\"Agent Simulation Summary\")\n",
    "print(f\"Total records: {len(agents_df):,}\")\n",
    "print(f\"Unique agents: {agents_df['agent_id'].nunique()}\")\n",
    "print(f\"Unique zones: {agents_df['room'].nunique()}\")\n",
    "print(f\"Simulation steps: {agents_df['step'].max() + 1}\")\n",
    "print(f\"\\nAgent type distribution:\")\n",
    "print(agents_df['agent_type'].value_counts())\n",
    "print(f\"\\nComfort metrics:\")\n",
    "print(f\"  Average comfort level: {agents_df['comfort_level'].mean():.2f}\")\n",
    "print(f\"  AC usage rate: {agents_df['using_ac'].mean()*100:.2f}%\")\n",
    "print(f\"  Average current temp: {agents_df['current_temp'].mean():.2f}째C\")\n",
    "print(f\"  Average preferred temp: {agents_df['preferred_temp'].mean():.2f}째C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AC usage over time\n",
    "ac_usage_by_step = agents_df.groupby('step')['using_ac'].mean()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(ac_usage_by_step.index, ac_usage_by_step.values * 100)\n",
    "plt.title('AC Usage Rate Over Simulation Time')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('AC Usage Rate (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(RESULTS_DIR / 'ac_usage_over_time.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature distribution by zone\n",
    "zone_temps = agents_df.groupby('room').agg({\n",
    "    'current_temp': ['mean', 'std'],\n",
    "    'using_ac': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "zone_temps.columns = ['avg_temp', 'std_temp', 'ac_usage_rate']\n",
    "zone_temps = zone_temps.sort_values('ac_usage_rate', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 zones by AC usage:\")\n",
    "print(zone_temps.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Profiling Analysis\n",
    "\n",
    "### 3.1 CUDA API Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CUDA API summary (if available)\n",
    "cuda_api_file = RESULTS_DIR / 'cuda_api_summary.csv'\n",
    "if cuda_api_file.exists():\n",
    "    cuda_api = pd.read_csv(cuda_api_file)\n",
    "    print(\"CUDA API Summary\")\n",
    "    print(cuda_api.head(20))\n",
    "    \n",
    "    # Look for cudaStreamSynchronize\n",
    "    if 'Function' in cuda_api.columns or 'Name' in cuda_api.columns:\n",
    "        name_col = 'Function' if 'Function' in cuda_api.columns else 'Name'\n",
    "        sync_calls = cuda_api[cuda_api[name_col].str.contains('Synchronize', na=False)]\n",
    "        if not sync_calls.empty:\n",
    "            print(\"\\n=== cudaStreamSynchronize Bottleneck Analysis ===\")\n",
    "            print(sync_calls)\n",
    "            print(\"\\nPer DREAM'26 paper: Expected ~66% of CUDA API time\")\n",
    "else:\n",
    "    print(\"CUDA API summary not found. Check nsys stats output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GPU Kernel Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPU kernel summary\n",
    "kernel_file = RESULTS_DIR / 'gpu_kernel_summary.csv'\n",
    "if kernel_file.exists():\n",
    "    kernels = pd.read_csv(kernel_file)\n",
    "    print(\"GPU Kernel Summary (Top 20)\")\n",
    "    print(kernels.head(20))\n",
    "    \n",
    "    # Look for NCCL kernels\n",
    "    if 'Name' in kernels.columns or 'Kernel' in kernels.columns:\n",
    "        name_col = 'Name' if 'Name' in kernels.columns else 'Kernel'\n",
    "        nccl_kernels = kernels[kernels[name_col].str.contains('nccl', case=False, na=False)]\n",
    "        if not nccl_kernels.empty:\n",
    "            print(\"\\n=== NCCL Communication Analysis ===\")\n",
    "            print(nccl_kernels)\n",
    "            print(\"\\nPer DREAM'26 paper:\")\n",
    "            print(\"  Expected AllGather: ~32.7% of GPU kernel time\")\n",
    "            print(\"  Expected AllReduce: ~31.7% of GPU kernel time\")\n",
    "else:\n",
    "    print(\"GPU kernel summary not found. Check nsys stats output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Memory Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load memory operation summary\n",
    "mem_file = RESULTS_DIR / 'memory_operation_summary.csv'\n",
    "if mem_file.exists():\n",
    "    mem_ops = pd.read_csv(mem_file)\n",
    "    print(\"Memory Operation Summary\")\n",
    "    print(mem_ops.head(20))\n",
    "    print(\"\\nPer DREAM'26 paper:\")\n",
    "    print(\"  Expected: Many small transfers (~37.5 bytes avg for H2D)\")\n",
    "    print(\"  Expected total: ~2.95 GB (2.32 GB D2H, 0.32 GB D2D)\")\n",
    "else:\n",
    "    print(\"Memory operation summary not found. Check nsys stats output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Energy Consumption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate energy consumption\n",
    "# Energy (kWh) = Power (W) * Time (hours) / 1000\n",
    "\n",
    "# Assuming 1 sample per second\n",
    "runtime_hours = len(gpu_baseline) / 3600\n",
    "\n",
    "for gpu_id in gpu_baseline['gpu_id'].unique():\n",
    "    gpu_data = gpu_baseline[gpu_baseline['gpu_id'] == gpu_id]\n",
    "    avg_power = gpu_data['power_draw_w'].mean()\n",
    "    energy_kwh = (avg_power * runtime_hours) / 1000\n",
    "    \n",
    "    print(f\"\\nGPU {gpu_id}:\")\n",
    "    print(f\"  Average power: {avg_power:.2f}W\")\n",
    "    print(f\"  Runtime: {runtime_hours:.2f} hours\")\n",
    "    print(f\"  Energy consumed: {energy_kwh:.4f} kWh\")\n",
    "\n",
    "# Total energy\n",
    "total_energy = (gpu_baseline['power_draw_w'].sum() * runtime_hours) / (1000 * len(gpu_baseline['gpu_id'].unique()))\n",
    "print(f\"\\nTotal GPU energy consumption: {total_energy:.4f} kWh\")\n",
    "\n",
    "# Load runtime info\n",
    "runtime_file = RESULTS_DIR / 'baseline_runtime.txt'\n",
    "if runtime_file.exists():\n",
    "    with open(runtime_file) as f:\n",
    "        runtime_sec = int(f.read().strip())\n",
    "        print(f\"\\nTotal simulation runtime: {runtime_sec} seconds ({runtime_sec/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bottleneck Identification Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load automated analysis if available\n",
    "summary_file = RESULTS_DIR / 'baseline_analysis_summary.json'\n",
    "if summary_file.exists():\n",
    "    with open(summary_file) as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"BASELINE ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(json.dumps(summary, indent=2))\n",
    "else:\n",
    "    print(\"Automated summary not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison with DREAM'26 Paper Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Metric': [\n",
    "        'cudaStreamSynchronize overhead',\n",
    "        'NCCL AllGather (% of GPU kernel time)',\n",
    "        'NCCL AllReduce (% of GPU kernel time)',\n",
    "        'Total NCCL communication',\n",
    "        'Average H2D transfer size',\n",
    "        'Primary CPU process usage',\n",
    "        'Secondary CPU process usage'\n",
    "    ],\n",
    "    'DREAM\\'26 Paper': [\n",
    "        '66.3% of CUDA API time',\n",
    "        '32.7%',\n",
    "        '31.7%',\n",
    "        '64.4%',\n",
    "        '37.5 bytes',\n",
    "        '96.99%',\n",
    "        '2.02%'\n",
    "    ],\n",
    "    'This Experiment': [\n",
    "        'TBD - Check nsys report',\n",
    "        'TBD - Check nsys report',\n",
    "        'TBD - Check nsys report',\n",
    "        'TBD - Check nsys report',\n",
    "        'TBD - Check nsys report',\n",
    "        'TBD - Check logs',\n",
    "        'TBD - Check logs'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON WITH DREAM'26 PAPER\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\nNote: Open the .nsys-rep file in Nsight Systems GUI for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations\n",
    "\n",
    "Based on the DREAM'26 paper and this baseline analysis:\n",
    "\n",
    "### Key Bottlenecks Identified:\n",
    "1. **cudaStreamSynchronize overhead** - Blocks GPU-CPU concurrency\n",
    "2. **NCCL communication dominates GPU time** - More time syncing than computing\n",
    "3. **Small, fragmented memory transfers** - Poor PCIe bandwidth utilization\n",
    "4. **CPU workload imbalance** - Secondary process underutilized\n",
    "5. **Host-side blocking** - CPU threads waiting instead of working\n",
    "\n",
    "### Optimization Opportunities:\n",
    "1. **Batch data transfers** - Reduce number of small transfers\n",
    "2. **Overlap communication with computation** - Use asynchronous operations\n",
    "3. **Reduce synchronization frequency** - Balance accuracy vs. performance\n",
    "4. **Load balancing** - Better distribute work across CPU processes\n",
    "5. **Optimize NCCL collective operations** - Tune AllGather/AllReduce patterns\n",
    "\n",
    "### Next Experiments:\n",
    "1. Test different data exchange frequencies\n",
    "2. Implement batched memory transfers\n",
    "3. Evaluate async communication patterns\n",
    "4. Profile with different GPU counts\n",
    "5. Test energy-aware scheduling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
